{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building reaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too long to run. Better read from local machine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cypher\n",
    "import os\n",
    "\n",
    "Con=\"http://neo4j:reactome@localhost:7474/db/data\" #database connection\n",
    "\n",
    "\n",
    "## path\n",
    "notebook_path = os.path.abspath(\"NetworkAnalysis_1.ipynb\")\n",
    "path=notebook_path.rsplit('/',1)\n",
    "path1=path[0]+'/Reaction_Connectivity/'\n",
    "path2=path[0]+'/Integrative_Analysis/'\n",
    "\n",
    "#run query for Reaction ID-Name map\n",
    "ReactionIDName_CQ=\"\"\"\n",
    "MATCH (re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT re.stId AS Reaction_ID, re.displayName AS Reaction_Name\n",
    "\"\"\"\n",
    "ReactionIDNameMap_DF=cypher.run(ReactionIDName_CQ,conn=Con).get_dataframe()\n",
    "ReactionIDNameMap_Dict=ReactionIDNameMap_DF.set_index('Reaction_ID')['Reaction_Name'].to_dict()\n",
    "\n",
    "\n",
    "#Analyze missing connections for all of Reactome\n",
    "\n",
    "#run query to get precedingEvents connections\n",
    "Preced_CQ=\"\"\"\n",
    "MATCH(pa:TopLevelPathway)-[:hasEvent*]->(ev:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "MATCH(ev)-[:precedingEvent]->(pe:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT pe.stId AS First_Reaction, ev.stId AS Second_Reaction\n",
    "\"\"\"\n",
    "Preced_DF=cypher.run(Preced_CQ,conn=Con).get_dataframe()\n",
    "\n",
    "#run query to get reactions connected by shared entities\n",
    "Shared_CQ=\"\"\"\n",
    "///query for non-set reactions\n",
    "MATCH(pa1:TopLevelPathway)-[:hasEvent*]->(ro1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po1:PhysicalEntity)\n",
    "WHERE NOT (po1.schemaClass=\"DefinedSet\" OR po1.schemaClass=\"CandidateSet\" OR po1.stId=\"R-HSA-113595\") //ignore Ub\n",
    "WITH pa1, ro1, po1\n",
    "MATCH(pa1)-[:hasEvent*]->(ri1:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "WITH ro1, po1, ri1\n",
    "MATCH(po1)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity*]-(ri1)\n",
    "WITH ro1, ri1, po1\n",
    "RETURN DISTINCT ro1.stId AS First_Reaction, ri1.stId AS Second_Reaction, po1.schemaClass AS SharedEntityClass, po1.displayName AS SharedEntityName, po1.stId AS SharedEntityID\n",
    "ORDER BY ro1.stId\n",
    "//query for set connectors\n",
    "UNION MATCH(pa2:TopLevelPathway)-[:hasEvent*]->(ro2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:output]->(po2a:PhysicalEntity)-[:hasMember|hasCandidate|physicalEntity*]->(po2b:PhysicalEntity)\n",
    "WHERE (po2a.schemaClass=\"DefinedSet\" OR po2a.schemaClass=\"CandidateSet\") AND NOT (po2a.stId=\"R-HSA-113595\") //ignore Ub\n",
    "WITH pa2, ro2, po2b\n",
    "MATCH(pa2)-[:hasEvent*]->(ri2:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "MATCH(po2b)<-[:input|catalystActivity|regulatedBy|regulator|physicalEntity|hasMember|hasCandidate*]-(ri2)\n",
    "WITH ro2, ri2, po2b\n",
    "RETURN DISTINCT ro2.stId AS First_Reaction, ri2.stId AS Second_Reaction, po2b.schemaClass AS SharedEntityClass, po2b.displayName AS SharedEntityName, po2b.stId AS SharedEntityID\n",
    "ORDER BY ro2.stId\n",
    "\"\"\"   \n",
    "Shared_DF=cypher.run(Shared_CQ,conn=Con).get_dataframe()\n",
    "#print('Shared_DF size: ',Shared_DF.shape)\n",
    "\n",
    "Preced_DF.to_csv(path2+'PrecedEvent_ReactionLinks_v76.csv',index=False,header=True)\n",
    "Shared_DF.to_csv(path2+'SharedEntities__ReactionLinks_v76.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cypher\n",
    "import os\n",
    "\n",
    "Con=\"http://neo4j:reactome@localhost:7474/db/data\" #database connection\n",
    "\n",
    "\n",
    "## path\n",
    "notebook_path = os.path.abspath(\"NetworkAnalysis_1.ipynb\")\n",
    "path=notebook_path.rsplit('/',1)\n",
    "path1=path[0]+'/Reaction_Connectivity/'\n",
    "path2=path[0]+'/Integrative_Analysis/'\n",
    "\n",
    "## read data\n",
    "Preced_DF = pd.read_csv(path2+'PrecedEvent_ReactionLinks_v76.csv')\n",
    "Shared_DF = pd.read_csv(path2+'SharedEntities__ReactionLinks_v76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes:12322\n",
      "Total edges:115913\n"
     ]
    }
   ],
   "source": [
    "edges_df = pd.concat([Preced_DF,Shared_DF[['First_Reaction','Second_Reaction']]])\n",
    "nodes = pd.Series.append(edges_df['First_Reaction'],edges_df['Second_Reaction'])\n",
    "\n",
    "# get key value from dict using values\n",
    "def Val2Key(Dict,Val):\n",
    "    return list(Dict.keys())[list(Dict.values()).index(Val)]\n",
    "\n",
    "# plot network\n",
    "def Plot_Network(Graph):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    Labels={i:i for i in dict(Graph.nodes)}\n",
    "    num=len(list(Graph.nodes)) # number of legend items in one row \n",
    "    siz = len(list(Graph.nodes))\n",
    "    fig, ax = plt.subplots(figsize=(20,16),dpi=70)\n",
    "    patches_list2=[mpatches.Patch(color='gold',label=str(key)+': '+str(Val2Key(Node_Labels,key))) for key in Graph.nodes]\n",
    "    pos = nx.kamada_kawai_layout(Graph)\n",
    "    ed_col=[Graph.get_edge_data(u,v)[0]['color'] for u,v in Graph.edges()]\n",
    "    nx.draw_networkx_nodes(Graph, pos, ax = ax, labels=True, node_color='gold',node_size=int(1e04/siz),alpha=1)\n",
    "    nx.draw_networkx_edges(Graph, pos, width=5, ax=ax, edge_color=ed_col,arrowsize=35)\n",
    "    _ = nx.draw_networkx_labels(Graph, pos, Labels, ax=ax,font_size=15)\n",
    "    plt.legend(handles=patches_list2,loc='best',ncol=int((num+50)/50),bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "    #return()\n",
    "    \n",
    "# create a directed self-loop network\n",
    "import networkx as nx\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# create nodes\n",
    "Nodes = pd.Series.append(edges_df['First_Reaction'],edges_df['Second_Reaction'])\n",
    "Nodes.drop_duplicates(inplace=True)\n",
    "\n",
    "# create dictionaries for labels and colours\n",
    "Node_Labels = {v:i+1 for i,v in enumerate(Nodes)}\n",
    "\n",
    "# add nodes to network\n",
    "[G.add_node(Node_Labels[i]) for i in Nodes]\n",
    "print(f\"Total nodes:{len(list(G.nodes()))}\")\n",
    "\n",
    "# add edges to network\n",
    "[G.add_edge(Node_Labels[row['First_Reaction']],Node_Labels[row['Second_Reaction']],color='gray') for label,row in edges_df.iterrows()]\n",
    "print(f\"Total edges:{len(list(G.edges()))}\")\n",
    "\n",
    "# visualize network\n",
    "#Plot_Network(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173421 rows affected.\n"
     ]
    }
   ],
   "source": [
    "#run query for Protein-Reaction map\n",
    "ProteinReaction_CQ=\"\"\"\n",
    "MATCH (re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})-[:input|output|catalystActivity|regulatedBy|regulator|hasMember|hasCandidate|hasComponent|physicalEntity*]->(pe:PhysicalEntity)-[:referenceEntity]->(uni:ReferenceEntity)\n",
    "RETURN DISTINCT uni.identifier AS Reference_ID, uni.displayName AS Reference_Name, pe.stId AS PE_ID, pe.displayName AS PE_Name, re.stId AS Reaction_ID, re.displayName AS Reaction_Name\n",
    "\"\"\"\n",
    "ProteinReactionMap_DF=cypher.run(ProteinReaction_CQ,conn=Con).get_dataframe()\n",
    "ProteinReactionMap_DF = ProteinReactionMap_DF[['Reference_ID','Reaction_ID']].groupby('Reference_ID')['Reaction_ID'].apply(list).reset_index(name='Reaction_IDs')\n",
    "ProteinReactionMap_Dict=ProteinReactionMap_DF.set_index('Reference_ID')['Reaction_IDs'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too long to run. Better read from local machine\n",
    "\n",
    "Start_Reactions = [Val2Key(Node_Labels,i[0]) for i in G.in_degree if i[1]==0]\n",
    "End_Reactions = [Val2Key(Node_Labels,i[0]) for i in G.out_degree if i[1]==0]\n",
    "\n",
    "\n",
    "All_Paths = []\n",
    "c = 0\n",
    "for s in Start_Reactions:\n",
    "    for e in End_Reactions:\n",
    "        if s in Node_Labels and e in Node_Labels:\n",
    "            if nx.has_path(G,Node_Labels[s],Node_Labels[e]):\n",
    "                #print(f\"s={s} e={e}\")\n",
    "                path_list = [Val2Key(Node_Labels,i) for i in nx.shortest_path(G,Node_Labels[s],Node_Labels[e])]\n",
    "                All_Paths.append(path_list)\n",
    "        c+=1\n",
    "        print(f\"Completed: {c}/{len(Start_Reactions)*len(End_Reactions)}\")\n",
    "Output_df = pd.DataFrame({'Paths':All_Paths})\n",
    "Output_df.to_csv(path2+'All_Shortest_Paths.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cypher\n",
    "import os\n",
    "\n",
    "Con=\"http://neo4j:reactome@localhost:7474/db/data\" #database connection\n",
    "\n",
    "## path\n",
    "notebook_path = os.path.abspath(\"NetworkAnalysis_1.ipynb\")\n",
    "path=notebook_path.rsplit('/',1)\n",
    "path1=path[0]+'/Reaction_Connectivity/'\n",
    "path2=path[0]+'/Integrative_Analysis/'\n",
    "\n",
    "# read all shortest paths\n",
    "Shortest_Paths = pd.read_csv(path2+'All_Shortest_Paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['R-HSA-5681987', 'R-HSA-8959573', 'R-HSA-8959...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['R-HSA-5681987', 'R-HSA-9664880']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['R-HSA-5681987', 'R-HSA-9664855']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['R-HSA-5681987', 'R-HSA-9664867']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['R-HSA-5681987', 'R-HSA-5205649', 'R-HSA-5205...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paths\n",
       "0  ['R-HSA-5681987', 'R-HSA-8959573', 'R-HSA-8959...\n",
       "1                 ['R-HSA-5681987', 'R-HSA-9664880']\n",
       "2                 ['R-HSA-5681987', 'R-HSA-9664855']\n",
       "3                 ['R-HSA-5681987', 'R-HSA-9664867']\n",
       "4  ['R-HSA-5681987', 'R-HSA-5205649', 'R-HSA-5205..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shortest_Paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Genes = {'Diabetes':['Q9UKG1','P41091','P26367'],\n",
    "                 'Diabetes_Mellitus_Insulin_Dependent':['P20823','Q13572','Q9Y2R2'],\n",
    "                 'Multiple_Myeloma':['P22607','P24385'],\n",
    "                 'Alzheimer_Disease_2':['P02649'],\n",
    "                 'Abortion_Habitual':['Q02930','Q8IZU3'],\n",
    "                 'Carcinoid_Tumor_Of_Lung':['O00255'],\n",
    "                 'L_Ferritin_Deficiency':['P02792'],\n",
    "                 'Extrinsic_Allergic_Alveolitis':['P04179'],\n",
    "                 'Dermatitis_Photoallergic':['O00116'],\n",
    "                 'Fatty_Liver_Disease_Nonalcoholic_Susceptibility_To_1':['Q9NST1'],\n",
    "                 'Nonalcoholic_Steatohepatitis':['P21439','Q92887','P12821','P07327','P00325','P08319','Q15848','P23526','P35869','P00352','P30837','P05091','P30038','Q9P2W7','P04040','Q6IB77','P08571','P50416','P04141','P05093','P05177','P05181','Q9BQI3','P00734','P25445','P49327','Q9NSA1','P14207','Q14749','P08263','P09488','P09211','P30711','Q9Y6K9','P01583','P08700','P05112','O60674','Q86Z14','P25391','P01130','P41159','P15018','P03956','Q16236','P15559','Q96RI1','O00482','Q16654','Q9UBM1','Q9NST1','Q07869','Q03181','P14222','P17612','P17252','Q05655','Q02156','P60484','P55895','P35241','Q8WTV0','P05120','Q96EB6','P36956','O76061','P01137','Q9BZW4','P20333','Q96RU7','P98155','P17861']\n",
    "                }\n",
    "\n",
    "disease = 'Nonalcoholic_Steatohepatitis'\n",
    "Disease_Reactions = [j for i in Disease_Genes[disease] if i in ProteinReactionMap_Dict for j in ProteinReactionMap_Dict[i]]\n",
    "End_Reactions = [Val2Key(Node_Labels,i[0]) for i in G.out_degree if i[1]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check reaction overlap in shortest paths\n",
    "\n",
    "Step_Count = []\n",
    "React_Match = []\n",
    "for p in Shortest_Paths['Paths']: \n",
    "    p_list = list(p.replace('[','').replace(']','').replace(\"'\",'').split(', '))\n",
    "    Step_Count.append(len(p_list))\n",
    "    t = 0\n",
    "    for d in list(set(Disease_Reactions)):\n",
    "        if d in p_list:\n",
    "            t+=1\n",
    "    React_Match.append(t)\n",
    "Shortest_Paths['Total_Steps'] = Step_Count\n",
    "Shortest_Paths[disease] = React_Match\n",
    "Shortest_Paths['Ratio_for_'+disease] = [i/j for i,j in zip(React_Match,Step_Count)]\n",
    "\n",
    "Shortest_Paths.sort_values('Ratio_for_'+disease,ascending=False,inplace=True)\n",
    "Shortest_Paths.reset_index(inplace=True)\n",
    "Shortest_Paths.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paths</th>\n",
       "      <th>Total_Steps</th>\n",
       "      <th>Nonalcoholic_Steatohepatitis</th>\n",
       "      <th>Ratio_for_Nonalcoholic_Steatohepatitis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['R-HSA-6789325', 'R-HSA-447226', 'R-HSA-89810...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['R-HSA-450074', 'R-HSA-450031', 'R-HSA-879942...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paths  Total_Steps  \\\n",
       "0  ['R-HSA-6789325', 'R-HSA-447226', 'R-HSA-89810...            3   \n",
       "1  ['R-HSA-450074', 'R-HSA-450031', 'R-HSA-879942...            6   \n",
       "2  ['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...           10   \n",
       "3  ['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...           10   \n",
       "4  ['R-HSA-1655825', 'R-HSA-1655834', 'R-HSA-1655...           10   \n",
       "\n",
       "   Nonalcoholic_Steatohepatitis  Ratio_for_Nonalcoholic_Steatohepatitis  \n",
       "0                             3                                     1.0  \n",
       "1                             6                                     1.0  \n",
       "2                            10                                     1.0  \n",
       "3                            10                                     1.0  \n",
       "4                            10                                     1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shortest_Paths.head()\n",
    "#Shortest_Paths.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run query for reaction ID-name map\n",
    "ReactionIDName_CQ=\"\"\"\n",
    "MATCH (re:ReactionLikeEvent{speciesName:\"Homo sapiens\"})\n",
    "RETURN DISTINCT re.stId AS ReactionID, re.displayName AS ReactionName\n",
    "\"\"\"\n",
    "ReacMap_DF=cypher.run(ReactionIDName_CQ,conn=Con).get_dataframe()\n",
    "ReacMap_Dict=ReacMap_DF.set_index('ReactionID')['ReactionName'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate path table\n",
    "\n",
    "Path_Score = []\n",
    "Path = []\n",
    "SR_Path = []\n",
    "ER_Path =[]\n",
    "Steps = []\n",
    "for i in Shortest_Paths['Ratio_for_'+disease].unique():\n",
    "    if i>0:\n",
    "        max_steps = max(Shortest_Paths[Shortest_Paths['Ratio_for_'+disease]==i][disease])\n",
    "        long_overlap_path = list(Shortest_Paths[(Shortest_Paths[disease]==max_steps) & (Shortest_Paths['Ratio_for_'+disease]==i)]['Paths'])\n",
    "        #print(f'Ratio: {i}')\n",
    "        if len(long_overlap_path)>1:\n",
    "            for j in long_overlap_path:\n",
    "                Path_Score.append(i)\n",
    "                path_list = list(j.replace('[','').replace(']','').replace(\"'\",'').split(', '))\n",
    "                SR_Path.append('=HYPERLINK(\"https://reactome.org/content/detail/'+str(path_list[0])+'\",\"'+str(ReacMap_Dict[path_list[0]])+'\")')\n",
    "                ER_Path.append('=HYPERLINK(\"https://reactome.org/content/detail/'+str(path_list[len(path_list)-1])+'\",\"'+str(ReacMap_Dict[path_list[len(path_list)-1]])+'\")')\n",
    "                Steps.append(len(path_list))\n",
    "                Path.append(j.replace('[','').replace(']','').replace(\"'\",'').replace(', ','-->'))\n",
    "        else:\n",
    "            Path_Score.append(i)\n",
    "            path_list = list(long_overlap_path[0].replace('[','').replace(']','').replace(\"'\",'').split(', '))\n",
    "            SR_Path.append('=HYPERLINK(\"https://reactome.org/content/detail/'+str(path_list[0])+'\",\"'+str(ReacMap_Dict[path_list[0]])+'\")')\n",
    "            ER_Path.append('=HYPERLINK(\"https://reactome.org/content/detail/'+str(path_list[len(path_list)-1])+'\",\"'+str(ReacMap_Dict[path_list[len(path_list)-1]])+'\")')\n",
    "            Steps.append(len(path_list))\n",
    "            Path.append(long_overlap_path[0].replace('[','').replace(']','').replace(\"'\",'').replace(', ','-->'))\n",
    "\n",
    "# write output to file\n",
    "Path_Table = pd.DataFrame(list(zip(SR_Path,ER_Path,Steps,Path_Score,Path)),columns=['Start_Reaction','End_Reaction','Steps','Score','Path'])\n",
    "#Path_Table.head()\n",
    "Path_Table.to_csv(path2+'Path_Scoring_'+disease+'.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13661 rows affected.\n"
     ]
    }
   ],
   "source": [
    "# Generate end reaction table\n",
    "\n",
    "Total_Reactions = len(Shortest_Paths[Shortest_Paths['Ratio_for_'+disease]>0])\n",
    "\n",
    "Reaction = []\n",
    "for row,label in Shortest_Paths.iterrows():\n",
    "    if label['Ratio_for_'+disease]>0:\n",
    "        p_list = list(label['Paths'].replace('[','').replace(']','').replace(\"'\",'').split(', '))\n",
    "        Reaction.append(p_list[len(p_list)-1])\n",
    "\n",
    "Reaction_Score = {}\n",
    "for i in Reaction:\n",
    "    if i in Reaction_Score:\n",
    "        Reaction_Score[i] = Reaction_Score[i]+1\n",
    "    else:\n",
    "        Reaction_Score[i] = 1\n",
    "Reaction_Score = {k:v/Total_Reactions for k,v in Reaction_Score.items()}\n",
    "\n",
    "# create dataframe\n",
    "Reaction_Table = pd.DataFrame(list(Reaction_Score.items()),columns=['End_Reaction','Score'])\n",
    "Reaction_Table.sort_values(by=['Score'],ascending=False,inplace=True)\n",
    "Reaction_Table.reset_index(inplace=True)\n",
    "Reaction_Table.drop(['index'],axis=1,inplace=True)\n",
    "Reaction_Table['End_Reaction']=Reaction_Table.End_Reaction.apply(lambda s: '=HYPERLINK(\"https://reactome.org/content/detail/'+str(s)+'\",\"'+str(ReacMap_Dict[s])+'\")')\n",
    "\n",
    "# write output to file\n",
    "Reaction_Table.to_csv(path2+'End_Reaction_Scoring_'+disease+'.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges = []\n",
    "paths = []\n",
    "for d in Disease_Reactions:\n",
    "    for e in End_Reactions:\n",
    "        if d in Node_Labels:\n",
    "            if nx.has_path(G,Node_Labels[d],Node_Labels[e]):\n",
    "                path = nx.shortest_path(G,Node_Labels[d],Node_Labels[e])\n",
    "                paths.append(path)\n",
    "                [sub_edges.append((path[i],path[i+1],0)) for i in range(len(path)-1)]\n",
    "                    \n",
    "H = G.edge_subgraph(sub_edges)\n",
    "print(len(list(H.nodes())),len(list(H.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_Network(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([len(i) for i in paths])\n",
    "print(f\"Total paths: {len(paths)}, Max steps: {max([len(i) for i in paths])}\")\n",
    "\n",
    "paths.sort(key=len,reverse=True)\n",
    "Path_End = [ReactionIDNameMap_Dict[Val2Key(Node_Labels,i[len(i)-1])] for i in paths]\n",
    "Path_End = list(dict.fromkeys(Path_End))\n",
    "Path_End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in paths:\n",
    "    if len(i)>=5:\n",
    "        p = []\n",
    "        for j in i:\n",
    "            p.append(ReactionIDNameMap_Dict[Val2Key(Node_Labels,j)])\n",
    "        print('-->'.join(map(str,p)))\n",
    "        print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
